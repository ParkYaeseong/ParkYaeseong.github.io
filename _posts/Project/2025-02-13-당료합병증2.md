---
title: 랜덤포레스트, Lasso & Ridge 회귀 분석
date: 2025-02-13 13:28:00 +09:00
categories: [Project, 당료합병증]
tags: [의료 데이터, Lasso, Ridge, 회귀분석, 다중공선성, 변수 선택, Feature Selecion]
---

<!-- _includes/head.html -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>

# ✅ Lasso & Ridge 회귀 분석 개요
Lasso와 Ridge 회귀는 **선형 회귀에서 다중공선성을 해결하고 변수 선택(Feature Selection)**을 할 때 유용한 정규화 기법입니다.

## 🔹 Lasso 회귀 (L1 정규화)
### 특징
- 불필요한 변수를 자동으로 0으로 만들어 제거하는 기능이 있음 (**변수 선택 기능**).
- 즉, 중요한 변수만 남김 → 해석력이 높아짐.
- 희소성(Sparsity)을 가지므로, 차원이 높은 데이터에 적합.

### 목적 함수 (Loss Function)
\[
\text{Minimize} \quad \sum_{i=1}^{n} (y_i - \hat{y_i})^2 + \lambda \sum_{j=1}^{p} |\beta_j|
\]
- **λ(람다)**: 정규화 강도 (클수록 더 많은 변수를 0으로 만듦)

---

## 🔹 Ridge 회귀 (L2 정규화)
### 특징
- 모든 변수를 유지하지만, 회귀 계수를 작게 조정하여 **다중공선성 해결**.
- 변수를 완전히 제거하지 않음 → **모든 변수가 예측에 기여**.
- 과적합(Overfitting)을 방지할 때 유용함.

### 목적 함수 (Loss Function)
\[
\text{Minimize} \quad \sum_{i=1}^{n} (y_i - \hat{y_i})^2 + \lambda \sum_{j=1}^{p} \beta_j^2
\]
- **λ(람다)**: 정규화 강도 (클수록 가중치를 더 작게 만듦)

---

# ✅ Lasso & Ridge 적용 설명
1. **One-Hot Encoding**을 통해 범주형 변수를 숫자로 변환 → 다중공선성 문제 가능성 있음.
2. `cv.glmnet()`을 이용해 **Cross Validation**을 수행하여 최적의 λ를 찾음.
3. 최적의 λ를 사용해 **Lasso & Ridge 모델을 학습**.
4. **변수 중요도 확인 후**, 변수를 줄여서 다시 모델 학습.

---

# ✅ 변수 중요도를 반영한 모델 개선
## 🔹 주요 변수만 선택하여 모델 학습
Lasso를 이용해 **중요도가 높은 변수만 유지**하고 나머지는 제거합니다.

## 🔹 코드 수정 방향
1. Lasso를 이용해 **변수 중요도가 높은 변수만 선택**.
2. 선택된 변수를 사용하여 **로지스틱 회귀 & 랜덤 포레스트 모델 학습**.