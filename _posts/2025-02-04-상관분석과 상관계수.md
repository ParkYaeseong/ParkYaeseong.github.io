---
title: "상관분석(Correlation Analysis) 정리"
date: 2025-02-04 01:00:00 +09:00
categories: [R, 데이터]
tags: [R, R Studion, 상관분석, 상관계수수]
---
<!-- _includes/head.html -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>

오늘은 **상관분석(Correlation Analysis)**에 대해 공부한 내용을 정리해보겠습니다. 데이터 분석에서 변수 간의 관계를 이해하는 것은 매우 중요한데요, 상관분석은 두 변수 간의 선형적 관계를 측정하는 데 사용되는 기본적이면서도 강력한 방법입니다. 이번 포스팅에서는 상관분석의 기본 개념부터 다양한 상관계수, 척도, 고유값 분해 등을 다루어보려고 합니다.

---

## 1. 상관분석이란?
상관분석은 **종속변수와 독립변수** 간의 관계를 분석하는 방법 중 하나입니다. 여기서 주의할 점은 **다중공선성**이나 **노이즈**, **자기상관** 등의 문제가 발생할 수 있다는 것입니다. 특히 시계열 데이터에서는 이전 데이터가 이후 데이터에 영향을 미치는 **자기상관** 현상을 고려해야 합니다.

---

## 2. 분산, 공분산, 상관계수
### - **분산(Variance)**
- 하나의 변수가 평균에서 얼마나 떨어져 있는지 측정합니다.
- 공식:  
  $$\text{분산} = \frac{\sum_{i=1}^n (x_i - \bar{x})^2}{n-1}$$

### - **공분산(Covariance)**
- 두 변수가가 **함께 변하는 정도**를 나타냅니다.  
- 공식:  
  $$S_{xy} = \frac{\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{n-1}$$
- 범위: -∞ ~ +∞ (단위에 의존적).

### - **상관계수(Correlation Coefficient)**
- 공분산을 표준화하여 단위의 영향을 제거한 값입니다.  
- 공식:  
  $$\text{상관계수} = \frac{\text{cov}(X,Y)}{\sigma_x \sigma_y}$$
- 범위: -1 ~ +1.  
  - **1**: 완전한 양의 상관관계  
  - **-1**: 완전한 음의 상관관계  
  - **0**: 선형 관계 없음

---

## 3. 상관계수의 종류
### - **피어슨 상관계수(Pearson's 𝜸)**  
  - **연속형 데이터**에 사용되며, 정규성을 가정합니다(모수적 방법).  
  - 검정 방법: t-test.

### - **스피어만 상관계수(Spearman's 𝜌)**  
  - **순위형 데이터**나 정규분포를 따르지 않는 연속형 데이터에 사용됩니다(비모수적 방법).  
  - 검정 방법: Kruskal-Wallis test.

### - **켄달 상관계수(Kendall's 𝜏)**  
  - 순위 데이터에 적용되며, 작은 데이터셋에 강점을 가집니다.

---

## 4. 척도(Scale)의 종류
- **이산형 척도**  
  - **명목 척도**: 이름만 부여된 데이터 (예: 성별).  
  - **순위 척도**: 순서만 의미가 있는 데이터 (예: 학년).

- **연속형 척도**  
  - **등간 척도**: 간격이 일정하지만 절대적 0점이 없음 (예: 온도).  
  - **비율 척도**: 절대적 0점이 존재하며 비율 계산 가능 (예: 무게, 나이).

---

## 5. 상관계수 행렬과 고유값 분해
### - **상관계수 행렬**  
  - 정방행렬이며 대칭행렬입니다.  
  - 각 행과 열은 변수 간의 상관계수를 나타냅니다.

### - **고유값 분해(Eigen Decomposition)**  
  - 상관계수 행렬을 **고유값(분산의 크기)**과 **고유벡터(방향)**로 분해합니다.  
  - **고유값**: 0.85 이상이면 주성분(Principal Component), 이하는 노이즈로 간주됩니다.  
  - **고유벡터**: 서로 정직교하며, 내적 시 0입니다.  
  - **주성분 분석(PCA)**을 통해 고차원 데이터를 저차원으로 축소할 수 있습니다.

---

## 언더피팅 (Underfitting)
- **정의**: 모델이 데이터의 패턴을 충분히 학습하지 못한 상태
- **원인**: 모델의 복잡도가 낮거나, 훈련 데이터가 충분하지 않을 때 발생
- **결과**: 훈련 데이터와 테스트 데이터 모두에서 낮은 성능

## 오버피팅 (Overfitting)
- **정의**: 모델이 훈련 데이터에 과적합된 상태
- **원인**: 모델의 복잡도가 너무 높거나, 훈련 데이터가 적을 때 발생
- **결과**: 훈련 데이터에서 높은 성능, 테스트 데이터에서 낮은 성능

## 일반화 오류 (Generalization Error)
- **정의**: 모델이 새로운 데이터(테스트 데이터)에서 얼마나 잘 예측하는지를 나타내는 지표
- **낮은 일반화 오류**: 모델이 잘 일반화되어 높은 성능을 보임
- **높은 일반화 오류**: 새로운 데이터에서 성능이 낮아지고, 오버피팅의 징후

## 일반화된 모델 (Generalized Model)
- **정의**: 훈련 데이터의 패턴을 학습하면서도, 새로운 데이터에서도 높은 성능을 보이는 모델
- **특징**:
  - 적절한 복잡도
  - 다양한 데이터에서 높은 예측 성능
  - 높은 데이터 일반화 능력


